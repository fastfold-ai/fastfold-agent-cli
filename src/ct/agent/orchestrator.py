"""
Multi-agent research orchestrator for ct.

Decomposes complex queries into N independent research threads, executes them
in parallel via ThreadPoolExecutor, shares findings through an EvidenceBoard,
and merges results into a single coherent report.

Single-agent by default. Multi-agent only when explicitly requested via
--agents N, /agents N, or auto-suggested for complex queries.
"""

import json
import logging
import threading
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
from dataclasses import dataclass, field
from io import StringIO
from typing import Optional

from rich.console import Console
from rich.live import Live
from rich.panel import Panel
from rich.text import Text

from ct.agent.evidence_board import EvidenceBoard
from ct.agent.session import Session
from ct.agent.trajectory import Trajectory
from ct.agent.types import ExecutionResult, Plan, Step
from ct.ui.status import ThinkingStatus

logger = logging.getLogger("ct.orchestrator")


# ─── Data structures ────────────────────────────────────────

@dataclass
class ThreadGoal:
    """A research angle for a single thread."""
    thread_id: int
    angle: str          # e.g. "Target Biology"
    goal: str           # Specific research question for this thread
    suggested_tools: list[str] = field(default_factory=list)
    context: str = ""   # Additional context/instructions


@dataclass
class ThreadResult:
    """Result from a single research thread."""
    thread_id: int
    goal: str
    plan: Optional[Plan] = None
    raw_results: dict = field(default_factory=dict)
    completed_steps: int = 0
    failed_steps: int = 0
    duration_s: float = 0.0
    error: Optional[str] = None


@dataclass
class OrchestratorResult:
    """Final merged result from all research threads."""
    threads: list[ThreadResult] = field(default_factory=list)
    merged_plan: Optional[Plan] = None
    summary: str = ""
    raw_results: dict = field(default_factory=dict)
    duration_s: float = 0.0
    n_threads: int = 0
    total_steps: int = 0
    completed_steps: int = 0
    failed_steps: int = 0
    metadata: dict = field(default_factory=dict)

    def to_markdown(self) -> str:
        """Generate a markdown report from the orchestrated results."""
        lines = []

        # Metadata header (if populated)
        md = self.metadata
        if md:
            lines.append("<!--")
            lines.append("  Report Metadata (machine-readable provenance)")
            for key in ("query", "timestamp", "model", "execution_time_s",
                         "tool_success_rate", "profile", "ct_version"):
                if key in md:
                    lines.append(f"  {key}: {md[key]}")
            lines.append("-->")
            lines.append("")
            lines.append("| Metadata | Value |")
            lines.append("|----------|-------|")
            if "timestamp" in md:
                lines.append(f"| Generated | {md['timestamp']} |")
            if "model" in md:
                lines.append(f"| Model | {md['model']} |")
            if "execution_time_s" in md:
                lines.append(f"| Execution Time | {md['execution_time_s']:.1f}s |")
            if "tool_success_rate" in md:
                lines.append(f"| Tool Success Rate | {md['tool_success_rate']} |")
            if "profile" in md:
                lines.append(f"| Profile | {md['profile']} |")
            if "ct_version" in md:
                lines.append(f"| ct Version | {md['ct_version']} |")
            lines.append("")

        lines.extend([
            f"# Multi-Agent Research Report",
            "",
            f"*Generated by ct multi-agent orchestrator ({self.n_threads} threads, "
            f"{self.duration_s:.1f}s)*",
            "",
        ])

        # Thread summary
        lines.append("## Research Threads")
        lines.append("")
        for tr in self.threads:
            status = "completed" if not tr.error else f"FAILED: {tr.error}"
            lines.append(
                f"- **Thread {tr.thread_id}** ({tr.goal[:80]}): "
                f"{tr.completed_steps} steps completed, "
                f"{tr.failed_steps} failed [{status}] ({tr.duration_s:.1f}s)"
            )
        lines.append("")

        # Main synthesis
        lines.append("---")
        lines.append("")
        lines.append(self.summary)
        lines.append("")

        # Detailed step results
        if self.merged_plan:
            lines.append("---")
            lines.append("")
            lines.append("## Detailed Step Results")
            lines.append("")
            for step in self.merged_plan.steps:
                status = "completed" if step.status == "completed" else "FAILED"
                lines.append(
                    f"### Step {step.id}: {step.description} [{status}]"
                )
                lines.append(f"Tool: `{step.tool}`")
                lines.append("")
                if step.result:
                    if isinstance(step.result, dict) and "summary" in step.result:
                        lines.append(step.result["summary"])
                    else:
                        lines.append(f"```\n{step.result}\n```")
                lines.append("")

        return "\n".join(lines)


# ─── Meta-planner prompt ────────────────────────────────────

META_PLANNER_SYSTEM_PROMPT = """\
You are ct's meta-planner for multi-agent parallel research.

Your job is to decompose a complex drug discovery query into N independent
research threads that can run in parallel. Each thread should focus on a
different angle or domain of the question.

Guidelines:
- Make threads as independent as possible (minimal overlap)
- Assign complementary angles: biology vs chemistry vs clinical vs safety vs mechanism
- Each thread should have a clear, focused goal
- Suggest specific ct tools for each thread when possible
- Keep the number of threads to what was requested

Return ONLY a JSON array of thread goals. Example:
[
  {
    "angle": "Target Biology",
    "goal": "Investigate CRBN target biology: expression, dependencies, pathway context",
    "suggested_tools": ["target.druggability", "target.expression_profile", "target.coessentiality"]
  },
  {
    "angle": "Compound Chemistry",
    "goal": "Analyze lenalidomide SAR, scaffold, and similar compounds",
    "suggested_tools": ["chemistry.sar_analyze", "chemistry.similarity_search"]
  }
]

Return ONLY the JSON array, no other text.
"""


# ─── Orchestrator ───────────────────────────────────────────

class ResearchOrchestrator:
    """Orchestrates parallel multi-agent research threads."""

    def __init__(self, session: Session, n_threads: int = 3,
                 trajectory: Trajectory = None):
        self.session = session
        self.console = session.console
        max_threads = int(session.config.get("agent.parallel_max_threads", 5))
        self.n_threads = min(max(n_threads, 1), max_threads)
        self.trajectory = trajectory
        self.evidence_board = EvidenceBoard()

    def run(self, query: str, context: dict = None,
            preset_goals: list[ThreadGoal] = None) -> OrchestratorResult:
        """Execute a multi-agent parallel research query.

        1. Decompose query into N thread goals via meta-planner (or use preset_goals)
        2. Execute threads in parallel with shared evidence board
        3. Merge results with global step renumbering
        4. Synthesize merged report

        Parameters
        ----------
        query : str
            The research query.
        context : dict, optional
            Additional context for the query.
        preset_goals : list[ThreadGoal], optional
            Pre-defined research angles (skips LLM decomposition).
            Used by case studies and other curated workflows.
        """
        t0 = time.time()
        context = context or {}

        if preset_goals is not None:
            # Use pre-defined goals — skip LLM decomposition
            goals = preset_goals
            self.n_threads = len(goals)
            self.console.print(
                f"\n  [cyan]Multi-agent mode:[/cyan] using {len(goals)} "
                f"pre-defined research angles"
            )
        else:
            self.console.print(
                f"\n  [cyan]Multi-agent mode:[/cyan] decomposing into "
                f"{self.n_threads} parallel research threads..."
            )
            # 1. Decompose
            goals = self._decompose(query, context)

        self.console.print(
            f"  [cyan]Threads planned:[/cyan] "
            + ", ".join(f"[bold]{g.angle}[/bold]" for g in goals)
        )
        self.console.print()

        # 2. Execute threads in parallel
        thread_results = self._execute_threads(query, goals, context)

        # 3. Merge results
        merged_plan, merged_raw = self._merge_results(query, thread_results)

        # 4. Meta-synthesize using the executor's synthesis
        self.console.print(
            f"\n  [cyan]Synthesizing[/cyan] merged results from "
            f"{len(thread_results)} threads..."
        )

        from ct.agent.executor import Executor
        executor = Executor(self.session)
        summary = executor.synthesize(query, merged_plan, merged_raw, stream=True)

        duration = time.time() - t0

        # Compute stats
        total_steps = sum(tr.completed_steps + tr.failed_steps for tr in thread_results)
        completed_steps = sum(tr.completed_steps for tr in thread_results)
        failed_steps = sum(tr.failed_steps for tr in thread_results)

        result = OrchestratorResult(
            threads=thread_results,
            merged_plan=merged_plan,
            summary=summary,
            raw_results=merged_raw,
            duration_s=duration,
            n_threads=len(thread_results),
            total_steps=total_steps,
            completed_steps=completed_steps,
            failed_steps=failed_steps,
        )

        # Auto-save report
        self._auto_save_report(query, result)

        # Print stats
        self.console.print(
            f"\n  [dim]{len(thread_results)} threads | "
            f"{completed_steps}/{total_steps} steps | "
            f"{len(self.evidence_board)} evidence entries | "
            f"{duration:.1f}s[/dim]"
        )

        return result

    def _decompose(self, query: str, context: dict) -> list[ThreadGoal]:
        """Use LLM to decompose query into N independent thread goals."""
        llm = self.session.get_llm()

        context_str = ""
        if context:
            parts = []
            for k, v in context.items():
                parts.append(f"{k}: {v}")
            context_str = f"\n\nAdditional context:\n" + "\n".join(parts)

        user_msg = (
            f"Decompose this drug discovery query into exactly {self.n_threads} "
            f"independent, parallel research threads:\n\n"
            f"Query: {query}{context_str}\n\n"
            f"Return a JSON array with {self.n_threads} thread goals."
        )

        with ThinkingStatus(self.console, "decomposing"):
            response = llm.chat(
                system=META_PLANNER_SYSTEM_PROMPT,
                messages=[{"role": "user", "content": user_msg}],
                temperature=0.3,
                max_tokens=2000,
            )

        text = (response.content or "").strip()

        # Parse JSON
        try:
            # Find JSON array in response
            start = text.index("[")
            end = text.rindex("]") + 1
            goals_data = json.loads(text[start:end])
        except (ValueError, json.JSONDecodeError):
            logger.warning("Meta-planner returned unparseable JSON, falling back to single thread")
            return [ThreadGoal(
                thread_id=1,
                angle="Full Research",
                goal=query,
            )]

        goals = []
        for i, g in enumerate(goals_data[:self.n_threads], start=1):
            goals.append(ThreadGoal(
                thread_id=i,
                angle=g.get("angle", f"Thread {i}"),
                goal=g.get("goal", query),
                suggested_tools=g.get("suggested_tools", []),
                context=g.get("context", ""),
            ))

        if not goals:
            goals = [ThreadGoal(thread_id=1, angle="Full Research", goal=query)]

        return goals

    def _execute_threads(self, query: str, goals: list[ThreadGoal],
                         context: dict) -> list[ThreadResult]:
        """Execute all thread goals in parallel using ThreadPoolExecutor."""
        thread_results: list[ThreadResult] = []
        # Track per-thread status for live display.
        statuses: dict[int, str] = {g.thread_id: "pending" for g in goals}
        step_counts: dict[int, tuple[int, int]] = {g.thread_id: (0, 0) for g in goals}
        details: dict[int, str] = {g.thread_id: "queued" for g in goals}
        start_times: dict[int, float] = {}
        durations: dict[int, float] = {}
        state_lock = threading.Lock()

        spinner_frames = ["-", "\\", "|", "/"]

        def _progress_callback(thread_id: int):
            """Build a thread-local progress callback for AgentLoop.run."""
            def _cb(event: str, **payload):
                with state_lock:
                    if statuses.get(thread_id) in {"completed", "failed"}:
                        return

                    if event == "planning_start":
                        details[thread_id] = "planning"
                        return
                    if event == "planned":
                        details[thread_id] = f"planned {payload.get('step_count', 0)} step(s)"
                        return
                    if event == "execution_start":
                        details[thread_id] = f"executing (iteration {payload.get('iteration', 1)})"
                        return
                    if event == "step_running":
                        details[thread_id] = (
                            f"step {payload.get('step_id', '?')} running: "
                            f"{payload.get('tool', '')}"
                        )
                        return
                    if event == "step_completed":
                        completed = int(payload.get("completed_steps", step_counts[thread_id][0]))
                        failed = int(payload.get("failed_steps", step_counts[thread_id][1]))
                        step_counts[thread_id] = (completed, failed)
                        details[thread_id] = (
                            f"step {payload.get('step_id', '?')} completed: "
                            f"{payload.get('tool', '')}"
                        )
                        return
                    if event == "step_failed":
                        completed = int(payload.get("completed_steps", step_counts[thread_id][0]))
                        failed = int(payload.get("failed_steps", step_counts[thread_id][1]))
                        step_counts[thread_id] = (completed, failed)
                        err = payload.get("error")
                        details[thread_id] = (
                            f"step {payload.get('step_id', '?')} failed: {payload.get('tool', '')}"
                            + (f" ({err})" if err else "")
                        )
                        return
                    if event == "replan":
                        details[thread_id] = "replanning after observer feedback"
                        return
                    if event == "replanned":
                        details[thread_id] = f"replanned {payload.get('step_count', 0)} step(s)"
                        return
                    if event == "synthesis_start":
                        details[thread_id] = "synthesizing thread findings"
                        return
                    if event == "synthesis_interrupted":
                        details[thread_id] = "synthesis interrupted"
                        return
                    if event == "synthesis_end":
                        details[thread_id] = "thread synthesis complete"
                        return
            return _cb

        def update_display():
            """Render the multi-thread progress panel."""
            lines = Text()
            lines.append("Multi-Agent Research\n\n")
            now = time.time()
            with state_lock:
                status_snapshot = dict(statuses)
                count_snapshot = dict(step_counts)
                detail_snapshot = dict(details)
                start_snapshot = dict(start_times)
                duration_snapshot = dict(durations)

            spinner = spinner_frames[int(now * 8) % len(spinner_frames)]
            running_threads = 0
            for g in goals:
                status = status_snapshot[g.thread_id]
                completed, failed = count_snapshot[g.thread_id]
                detail = detail_snapshot[g.thread_id]
                if status == "running":
                    running_threads += 1
                    elapsed = max(0.0, now - start_snapshot.get(g.thread_id, now))
                    lines.append("  [", style="")
                    lines.append(spinner, style="bold cyan")
                    lines.append("] ", style="")
                    lines.append(
                        (
                            f"Thread {g.thread_id}: {g.angle} "
                            f"({completed} completed, {failed} failed) "
                            f"- {detail} [{elapsed:.1f}s]"
                        ),
                        style="cyan",
                    )
                elif status == "completed":
                    lines.append("  [", style="")
                    lines.append("+", style="bold green")
                    lines.append("] ", style="")
                    elapsed = duration_snapshot.get(g.thread_id, 0.0)
                    lines.append(
                        (
                            f"Thread {g.thread_id}: {g.angle} "
                            f"({completed} completed, {failed} failed) "
                            f"- done [{elapsed:.1f}s]"
                        ),
                        style="green",
                    )
                elif status == "failed":
                    lines.append("  [", style="")
                    lines.append("!", style="bold red")
                    lines.append("] ", style="")
                    elapsed = duration_snapshot.get(g.thread_id, 0.0)
                    lines.append(
                        f"Thread {g.thread_id}: {g.angle} ({detail}) [{elapsed:.1f}s]",
                        style="red",
                    )
                else:
                    lines.append("  [ ] ", style="dim")
                    lines.append(
                        f"Thread {g.thread_id}: {g.angle} - {detail}",
                        style="dim",
                    )
                lines.append("\n")

            eb_count = len(self.evidence_board)
            lines.append(
                f"\n  Active threads: {running_threads}/{len(goals)}",
                style="dim",
            )
            if eb_count:
                lines.append(f"  |  Evidence board: {eb_count} entries", style="dim")

            return Panel(lines, title="Parallel Research", border_style="cyan")

        with Live(update_display(), console=self.console, refresh_per_second=6) as live:
            with ThreadPoolExecutor(max_workers=self.n_threads) as pool:
                futures = {}
                for goal in goals:
                    with state_lock:
                        statuses[goal.thread_id] = "running"
                        details[goal.thread_id] = "starting worker"
                        start_times[goal.thread_id] = time.time()
                    future = pool.submit(
                        self._execute_single_thread,
                        query,
                        goal,
                        context,
                        _progress_callback(goal.thread_id),
                    )
                    futures[future] = goal

                for future in as_completed(futures):
                    goal = futures[future]
                    try:
                        result = future.result()
                        thread_results.append(result)
                        with state_lock:
                            step_counts[goal.thread_id] = (
                                result.completed_steps, result.failed_steps
                            )
                            statuses[goal.thread_id] = (
                                "completed" if not result.error else "failed"
                            )
                            durations[goal.thread_id] = result.duration_s
                            if result.error:
                                details[goal.thread_id] = f"error: {result.error}"
                            else:
                                details[goal.thread_id] = "thread complete"
                    except Exception as e:
                        logger.error(
                            "Thread %d (%s) raised exception: %s",
                            goal.thread_id, goal.angle, e,
                        )
                        thread_results.append(ThreadResult(
                            thread_id=goal.thread_id,
                            goal=goal.goal,
                            error=str(e),
                        ))
                        with state_lock:
                            statuses[goal.thread_id] = "failed"
                            details[goal.thread_id] = f"error: {e}"
                            durations[goal.thread_id] = max(
                                0.0, time.time() - start_times.get(goal.thread_id, time.time())
                            )

                    live.update(update_display())

        # Sort by thread_id for consistent ordering
        thread_results.sort(key=lambda r: r.thread_id)
        return thread_results

    def _execute_single_thread(self, query: str, goal: ThreadGoal,
                               context: dict, progress_callback=None) -> ThreadResult:
        """Execute a single research thread (runs in a worker thread).

        Creates its own Session and AgentLoop for thread safety.
        """
        from ct.agent.config import Config
        from ct.agent.loop import AgentLoop

        t0 = time.time()

        # Each thread gets its own session with a silent console
        worker_console = Console(file=StringIO(), quiet=True)
        worker_config = Config.load()  # Fresh config copy
        worker_session = Session(config=worker_config, verbose=False)
        worker_session.console = worker_console

        # Create AgentLoop with evidence board and headless mode
        agent = AgentLoop(
            worker_session,
            evidence_board=self.evidence_board,
            thread_id=goal.thread_id,
            headless=True,
        )

        # Build thread-specific context
        thread_context = dict(context)
        thread_context["research_angle"] = goal.angle
        if goal.suggested_tools:
            thread_context["suggested_tools"] = ", ".join(goal.suggested_tools)

        try:
            result = agent.run(
                goal.goal,
                thread_context,
                progress_callback=progress_callback,
            )

            completed = [s for s in result.plan.steps if s.status == "completed"]
            failed = [s for s in result.plan.steps if s.status == "failed"]

            return ThreadResult(
                thread_id=goal.thread_id,
                goal=goal.goal,
                plan=result.plan,
                raw_results=result.raw_results,
                completed_steps=len(completed),
                failed_steps=len(failed),
                duration_s=time.time() - t0,
            )
        except Exception as e:
            logger.error("Thread %d failed: %s", goal.thread_id, e)
            if callable(progress_callback):
                try:
                    progress_callback("thread_error", error=str(e))
                except Exception:
                    pass
            return ThreadResult(
                thread_id=goal.thread_id,
                goal=goal.goal,
                duration_s=time.time() - t0,
                error=str(e),
            )

    def _merge_results(self, query: str,
                       thread_results: list[ThreadResult]) -> tuple[Plan, dict]:
        """Merge thread results with global step renumbering.

        Thread 1 steps 1-3 become global 1-3,
        Thread 2 steps 1-4 become global 4-7, etc.
        Step descriptions are prefixed with [Thread N: Angle] for provenance.
        """
        merged_steps: list[Step] = []
        merged_raw: dict = {}
        global_id = 1

        for tr in thread_results:
            if tr.error or tr.plan is None:
                continue

            # Find the angle from the goal
            angle = tr.goal[:40]

            for step in tr.plan.steps:
                # Create a new step with global ID and thread annotation
                new_step = Step(
                    id=global_id,
                    description=f"[Thread {tr.thread_id}: {angle}] {step.description}",
                    tool=step.tool,
                    tool_args=step.tool_args,
                    depends_on=[],  # No cross-thread deps
                    status=step.status,
                    result=step.result,
                )
                merged_steps.append(new_step)

                # Map results to new global IDs
                if step.id in tr.raw_results:
                    merged_raw[global_id] = tr.raw_results[step.id]

                global_id += 1

        merged_plan = Plan(
            query=query,
            steps=merged_steps,
        )

        return merged_plan, merged_raw

    def _auto_save_report(self, query: str, result: OrchestratorResult):
        """Auto-save the multi-agent report to the output directory."""
        import re
        from datetime import datetime
        from pathlib import Path

        try:
            output_base = self.session.config.get("sandbox.output_dir")
            output_dir = (
                Path(output_base) / "reports"
                if output_base
                else Path.cwd() / "outputs" / "reports"
            )
            output_dir.mkdir(parents=True, exist_ok=True)

            query_slug = re.sub(r'[^\w\s-]', '', query.lower())
            query_slug = re.sub(r'[\s]+', '_', query_slug.strip())[:60]
            if not query_slug:
                query_slug = "multi_agent_report"
            ts = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"{query_slug}_multi_{ts}.md"

            path = output_dir / filename
            counter = 2
            while path.exists():
                filename = f"{query_slug}_multi_{counter}.md"
                path = output_dir / filename
                counter += 1

            # Populate provenance metadata
            from datetime import timezone
            from ct import __version__

            cfg = self.session.config
            provider = cfg.get("llm.provider", "anthropic")
            model = cfg.get("llm.model", "unknown")
            profile = cfg.get("agent.profile", "research")
            success_str = f"{result.completed_steps}/{result.total_steps}"

            result.metadata = {
                "query": query,
                "timestamp": datetime.now(timezone.utc).isoformat(),
                "model": f"{provider}/{model}",
                "execution_time_s": result.duration_s,
                "tool_success_rate": success_str,
                "profile": profile,
                "ct_version": __version__,
            }

            report = result.to_markdown()
            path.write_text(report)
            self.console.print(f"  [dim]Report saved → {path}[/dim]")

            mode = str(getattr(self.session, "mode", "batch") or "batch").lower()
            if mode == "interactive":
                publish_html = bool(
                    self.session.config.get("output.auto_publish_html_interactive", True)
                )
            else:
                publish_html = bool(
                    self.session.config.get("output.auto_publish_html_batch", False)
                )
            if publish_html:
                from ct.reports.html import publish_report

                html_path = publish_report(path)
                self.console.print(f"  [dim]HTML report → {html_path}[/dim]")
        except Exception as exc:
            if self.session.verbose:
                self.console.print(
                    f"  [yellow]Could not auto-save report:[/yellow] {exc}"
                )
